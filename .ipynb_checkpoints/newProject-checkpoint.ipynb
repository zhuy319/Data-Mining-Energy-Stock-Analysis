{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76c05a44",
   "metadata": {},
   "source": [
    "### CSC 373 / 673: Assignment 4\n",
    "#### Author: Ruiwen Yang, Jiayi Zhou, Yi Zhu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a04d09",
   "metadata": {},
   "source": [
    "#### Project Task\n",
    "In the project, we want to organize a portfolio of energy companies. Our task is mainly about twelve renewable energy companies, but we also include five fossil fuel companies. Our list of twelve renewable energy companies is based on the article: https://simplywall.st/markets/us/utilities/renewable-energy. We add them because we think fossil fuel companies will have different trends compared to renewable energy; if we want to reduce the risk of our portfolio, adding fossil fuel companies can be a good option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77125a5c-382a-4446-9b07-bb45ef615c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as data\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import my_utils\n",
    "import clustering as clusterer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import BisectingKMeans\n",
    "import yellowbrick\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from yellowbrick.cluster import InterclusterDistance\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf890c35-4b4e-418c-8212-a79ecd542dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = 'yahoo'\n",
    "start_date = '2016-01-01'\n",
    "end_date = dt.date.today()\n",
    "#Ormat Technologies\n",
    "ORA = data.DataReader('ORA', data_source, start_date, end_date)\n",
    "#Montauk Renewables\n",
    "MNTK = data.DataReader('MNTK', data_source, start_date, end_date)\n",
    "#Vistra Corp\n",
    "VST = data.DataReader('VST', data_source, start_date, end_date)\n",
    "#The AES Corporation\n",
    "AES = data.DataReader('AES', data_source, start_date, end_date)\n",
    "#Altus Power\n",
    "AMPS = data.DataReader('AMPS', data_source, start_date, end_date)\n",
    "#VivoPower International PLC\n",
    "VVPR = data.DataReader('VVPR', data_source, start_date, end_date)\n",
    "#Clearway Energy Inc\n",
    "CWEN = data.DataReader('CWEN', data_source, start_date, end_date)\n",
    "#Sunnova Energy International Inc\n",
    "NOVA = data.DataReader('NOVA', data_source, start_date, end_date)\n",
    "#Atlantica Sustainable Infrastructure plc\n",
    "AY = data.DataReader('AY', data_source, start_date, end_date)\n",
    "#ReNew Energy Global Plc\n",
    "RNW = data.DataReader('RNW', data_source, start_date, end_date)\n",
    "#Azure Power Global Limited\n",
    "AZRE = data.DataReader('AZRE', data_source, start_date, end_date)\n",
    "#Eco Wave Power Global AB (publ)\n",
    "WAVE = data.DataReader('WAVE', data_source, start_date, end_date)\n",
    "#Ellomay Capital Ltd.\n",
    "ELLO = data.DataReader('ELLO', data_source, start_date, end_date)\n",
    "# fossil fuel companies\n",
    "#Ranger Oil Corporation\n",
    "ROCC = data.DataReader('ROCC', data_source, start_date, end_date)\n",
    "#Ormat Technologies, Inc\n",
    "ORA = data.DataReader('ORA', data_source, start_date, end_date)\n",
    "#NRG Energy, Inc\n",
    "NRG = data.DataReader('NRG', data_source, start_date, end_date)\n",
    "#Thermon Group Holdings, Inc\n",
    "THR = data.DataReader('THR', data_source, start_date, end_date)\n",
    "#USA Compression Partners, LP\n",
    "USAC = data.DataReader('USAC', data_source, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1127a71c-7192-46a8-93be-5a1105e3c931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['High', 'Low', 'Open', 'Close', 'Volume', 'Adj Close', 'High', 'Low',\n",
      "       'Open', 'Close', 'Volume', 'Adj Close', 'High', 'Low', 'Open', 'Close',\n",
      "       'Volume', 'Adj Close', 'High', 'Low', 'Open', 'Close', 'Volume',\n",
      "       'Adj Close', 'High', 'Low', 'Open', 'Close', 'Volume', 'Adj Close',\n",
      "       'High', 'Low', 'Open', 'Close', 'Volume', 'Adj Close', 'High', 'Low',\n",
      "       'Open', 'Close', 'Volume', 'Adj Close', 'High', 'Low', 'Open', 'Close',\n",
      "       'Volume', 'Adj Close', 'High', 'Low', 'Open', 'Close', 'Volume',\n",
      "       'Adj Close', 'High', 'Low', 'Open', 'Close', 'Volume', 'Adj Close',\n",
      "       'High', 'Low', 'Open', 'Close', 'Volume', 'Adj Close', 'High', 'Low',\n",
      "       'Open', 'Close', 'Volume', 'Adj Close', 'High', 'Low', 'Open', 'Close',\n",
      "       'Volume', 'Adj Close'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([ORA, MNTK, VST, AES, AMPS,VVPR,CWEN,NOVA,AY,RNW,AZRE,WAVE,ELLO], axis=1)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82795e23-5ddc-434c-9982-9aa64a6cc131",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['ORA','MNTK','VST','AES','AMPS','VVPR','CWEN','NOVA','AY','RNW','WAVE','ELLO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5236abcf-688b-4e12-ad55-be47beb928c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.set_axis(['High1','Low1', 'Open1', 'Close1','Volume1','Adj Close1','High2','Low2', 'Open2', 'Close2','Volume2','Adj Close2','High3','Low3', 'Open3', 'Close3','Volume3','Adj Close3','High4','Low4', 'Open4', 'Close4','Volume4','Adj Close4','High5','Low5', 'Open5', 'Close5','Volume5','Adj Close5','High6','Low6', 'Open6', 'Close6','Volume6','Adj Close6','High7','Low7', 'Open7', 'Close7','Volume7','Adj Close7','High8','Low8', 'Open8', 'Close8','Volume8','Adj Close8','High9','Low9', 'Open9', 'Close9','Volume9','Adj Close9','High10','Low10', 'Open10', 'Close10','Volume10','Adj Close10','High11','Low11', 'Open11', 'Close11','Volume11','Adj Close11','High12','Low12', 'Open12', 'Close12','Volume12','Adj Close12','High13','Low13', 'Open13', 'Close13','Volume13','Adj Close13'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2af69422-f9fe-457f-9b16-4909ae35b902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to prepare animal data for clustering\n",
    "def adjust_feature_types(dataset):\n",
    "    # convert numeric features into float64\n",
    "    numeric_columns = dataset.select_dtypes('number').columns\n",
    "    for column in numeric_columns:\n",
    "        dataset = dataset.astype({column: 'float64'})\n",
    "    # convert object features into categorical\n",
    "    obj_cols = dataset.select_dtypes('object').columns\n",
    "    for column in obj_cols:\n",
    "        dataset = dataset.astype({column: 'category'})\n",
    "    # apply one hot encoding for animal species and commodity\n",
    "    dataset = my_utils.encode_features(dataset)     \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c46359e-abf9-4f4f-8443-845385a37c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_utils\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def prepare_data(dataset):\n",
    "    dataset = adjust_feature_types(dataset)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def clean_data(data):\n",
    "    origlen = data.shape[0]\n",
    "    print(\"Original number of instances is \", origlen)\n",
    "    data = my_utils.remove_outliers(data, num_std=5)\n",
    "    print(\"Number of removed outliers further than 5 standard deviation from the mean is \",(origlen-data.shape[0]))\n",
    "    data = data.drop_duplicates()\n",
    "    print(\"Number of removed duplicated instances is \",(origlen-data.shape[0]))\n",
    "    data = my_utils.remove_miss_columns(data)\n",
    "    print(\"Number of values with NA being interpolated is \",data.isna().sum().sum())\n",
    "    data = data.interpolate('linear')\n",
    "    return data\n",
    "    \n",
    "class Preprocessor:\n",
    "    # initialize constructors\n",
    "    def __init__(self):\n",
    "    # For instance operations\n",
    "        # parameter for remove outliers\n",
    "        self.feature_means = None\n",
    "        self.feature_std = None\n",
    "    \n",
    "    # For feature operations\n",
    "        # parameter for selected features\n",
    "        self.selected_features = None\n",
    "        # parameter for kselected features\n",
    "        self.kselected_features = None\n",
    "    \n",
    "    # For value operations\n",
    "        # parameter for scale values\n",
    "        self.scaler = preprocessing.StandardScaler()\n",
    "        self.pca = PCA(n_components = 2)\n",
    "    \n",
    "    # fit dataset and store constructor objects\n",
    "    def fit(self, data, X_clf, Y_clf, k, flags):\n",
    "        self.selected_features = my_utils.basic_features_selection(data).columns\n",
    "        numeric_columns = data[self.selected_features].select_dtypes('float64').columns\n",
    "        self.scaler = self.scaler.fit(data[numeric_columns])\n",
    "        if flags[0]==1:\n",
    "            self.kselected_features = my_utils.k_features_selection(data,X_clf,Y_clf,k).columns\n",
    "        if flags[1]==1:\n",
    "            self.pca = self.pca.fit(data[self.selected_features])\n",
    "        \n",
    "    # transform dataset with flags \n",
    "    def transform(self, data, flags):\n",
    "        data = data[self.selected_features]\n",
    "        numeric_columns = data.select_dtypes('float64').columns\n",
    "        data = data.copy()\n",
    "        data[numeric_columns] = self.scaler.transform(data[numeric_columns])\n",
    "        kbestdata = pd.DataFrame()\n",
    "        pcadata = pd.DataFrame()\n",
    "        if flags[0]==1:\n",
    "            kbestdata = data[self.kselected_features]\n",
    "        if flags[1]==1:\n",
    "            pcadata = self.pca.transform(data)\n",
    "        return data, kbestdata, pcadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e03c9fd-0ef5-4be3-906e-94eb2d09f776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['High1', 'Low1', 'Open1', 'Close1', 'Volume1', 'Adj Close1', 'High2',\n",
      "       'Low2', 'Open2', 'Close2', 'Volume2', 'Adj Close2', 'High3', 'Low3',\n",
      "       'Open3', 'Close3', 'Volume3', 'Adj Close3', 'High4', 'Low4', 'Open4',\n",
      "       'Close4', 'Volume4', 'Adj Close4', 'High5', 'Low5', 'Open5', 'Close5',\n",
      "       'Volume5', 'Adj Close5', 'High6', 'Low6', 'Open6', 'Close6', 'Volume6',\n",
      "       'Adj Close6', 'High7', 'Low7', 'Open7', 'Close7', 'Volume7',\n",
      "       'Adj Close7', 'High8', 'Low8', 'Open8', 'Close8', 'Volume8',\n",
      "       'Adj Close8', 'High9', 'Low9', 'Open9', 'Close9', 'Volume9',\n",
      "       'Adj Close9', 'High10', 'Low10', 'Open10', 'Close10', 'Volume10',\n",
      "       'Adj Close10', 'High11', 'Low11', 'Open11', 'Close11', 'Volume11',\n",
      "       'Adj Close11', 'High12', 'Low12', 'Open12', 'Close12', 'Volume12',\n",
      "       'Adj Close12', 'High13', 'Low13', 'Open13', 'Close13', 'Volume13',\n",
      "       'Adj Close13'],\n",
      "      dtype='object')\n",
      "Original number of instances is  1725\n",
      "Number of removed outliers further than 7 standard deviation from the mean is  1397\n",
      "Number of removed duplicated instances is  1397\n",
      "Number of values with NA being interpolated is  0\n"
     ]
    }
   ],
   "source": [
    "dataset = prepare_data(df2)\n",
    "print(dataset.columns)\n",
    "flags = [0,1]\n",
    "\n",
    "# do basic cleaning on the dataset\n",
    "dataset = clean_data(dataset)\n",
    "\n",
    "# instantiate Preprocessor class\n",
    "preprocessor = Preprocessor()\n",
    "\n",
    "# fit the dataset and transform\n",
    "preprocessor.fit(dataset,None,None,0,flags)\n",
    "data, kbestdata, pcadata = preprocessor.transform(dataset,flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ccd75146-02b5-40f3-9a0a-6f5945f428f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 26)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b59a583-baa6-4d2b-9c36-7af966fb3cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High1</th>\n",
       "      <th>Volume1</th>\n",
       "      <th>High2</th>\n",
       "      <th>Volume2</th>\n",
       "      <th>High3</th>\n",
       "      <th>Volume3</th>\n",
       "      <th>High4</th>\n",
       "      <th>Volume4</th>\n",
       "      <th>High5</th>\n",
       "      <th>Volume5</th>\n",
       "      <th>...</th>\n",
       "      <th>High9</th>\n",
       "      <th>Volume9</th>\n",
       "      <th>High10</th>\n",
       "      <th>Volume10</th>\n",
       "      <th>High11</th>\n",
       "      <th>Volume11</th>\n",
       "      <th>High12</th>\n",
       "      <th>Volume12</th>\n",
       "      <th>High13</th>\n",
       "      <th>Volume13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-07-01</th>\n",
       "      <td>-0.914425</td>\n",
       "      <td>-0.308110</td>\n",
       "      <td>-1.387191</td>\n",
       "      <td>-0.683305</td>\n",
       "      <td>-1.260783</td>\n",
       "      <td>-0.324191</td>\n",
       "      <td>1.475940</td>\n",
       "      <td>-0.667879</td>\n",
       "      <td>0.363923</td>\n",
       "      <td>-0.994569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844598</td>\n",
       "      <td>-0.472524</td>\n",
       "      <td>1.409164</td>\n",
       "      <td>-0.879394</td>\n",
       "      <td>1.691564</td>\n",
       "      <td>-0.295883</td>\n",
       "      <td>4.321024</td>\n",
       "      <td>3.646284</td>\n",
       "      <td>1.284563</td>\n",
       "      <td>1.580122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-06</th>\n",
       "      <td>-1.084119</td>\n",
       "      <td>-0.161184</td>\n",
       "      <td>-1.484413</td>\n",
       "      <td>-0.723592</td>\n",
       "      <td>-1.239432</td>\n",
       "      <td>0.488350</td>\n",
       "      <td>1.380511</td>\n",
       "      <td>-0.947914</td>\n",
       "      <td>0.358200</td>\n",
       "      <td>-1.008901</td>\n",
       "      <td>...</td>\n",
       "      <td>1.090795</td>\n",
       "      <td>-0.697455</td>\n",
       "      <td>1.353711</td>\n",
       "      <td>-1.023265</td>\n",
       "      <td>1.760297</td>\n",
       "      <td>-0.085782</td>\n",
       "      <td>6.375461</td>\n",
       "      <td>9.436822</td>\n",
       "      <td>1.401762</td>\n",
       "      <td>0.295484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-07</th>\n",
       "      <td>-1.066565</td>\n",
       "      <td>-0.407582</td>\n",
       "      <td>-1.520953</td>\n",
       "      <td>-0.603332</td>\n",
       "      <td>-1.041453</td>\n",
       "      <td>2.979043</td>\n",
       "      <td>1.318762</td>\n",
       "      <td>-1.285036</td>\n",
       "      <td>0.335304</td>\n",
       "      <td>-1.016158</td>\n",
       "      <td>...</td>\n",
       "      <td>1.161541</td>\n",
       "      <td>0.076385</td>\n",
       "      <td>1.353711</td>\n",
       "      <td>-0.914688</td>\n",
       "      <td>1.442509</td>\n",
       "      <td>-0.065971</td>\n",
       "      <td>5.100747</td>\n",
       "      <td>1.914109</td>\n",
       "      <td>1.128299</td>\n",
       "      <td>-0.227887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-08</th>\n",
       "      <td>-1.118058</td>\n",
       "      <td>-0.128787</td>\n",
       "      <td>-1.609040</td>\n",
       "      <td>-0.639410</td>\n",
       "      <td>-1.223905</td>\n",
       "      <td>1.314301</td>\n",
       "      <td>1.184038</td>\n",
       "      <td>0.130427</td>\n",
       "      <td>0.346752</td>\n",
       "      <td>-1.014162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912515</td>\n",
       "      <td>-0.418365</td>\n",
       "      <td>1.314894</td>\n",
       "      <td>-1.020692</td>\n",
       "      <td>1.473237</td>\n",
       "      <td>-0.136613</td>\n",
       "      <td>4.866830</td>\n",
       "      <td>3.994090</td>\n",
       "      <td>0.996075</td>\n",
       "      <td>0.438222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-09</th>\n",
       "      <td>-1.088800</td>\n",
       "      <td>-0.857029</td>\n",
       "      <td>-1.527478</td>\n",
       "      <td>-0.708259</td>\n",
       "      <td>-1.027867</td>\n",
       "      <td>0.027247</td>\n",
       "      <td>1.150357</td>\n",
       "      <td>0.385179</td>\n",
       "      <td>0.381095</td>\n",
       "      <td>-0.994569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782341</td>\n",
       "      <td>-1.127800</td>\n",
       "      <td>1.329451</td>\n",
       "      <td>-0.899615</td>\n",
       "      <td>1.610702</td>\n",
       "      <td>-0.392853</td>\n",
       "      <td>3.913641</td>\n",
       "      <td>0.683074</td>\n",
       "      <td>1.191406</td>\n",
       "      <td>0.628538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               High1   Volume1     High2   Volume2     High3   Volume3  \\\n",
       "Date                                                                     \n",
       "2021-07-01 -0.914425 -0.308110 -1.387191 -0.683305 -1.260783 -0.324191   \n",
       "2021-07-06 -1.084119 -0.161184 -1.484413 -0.723592 -1.239432  0.488350   \n",
       "2021-07-07 -1.066565 -0.407582 -1.520953 -0.603332 -1.041453  2.979043   \n",
       "2021-07-08 -1.118058 -0.128787 -1.609040 -0.639410 -1.223905  1.314301   \n",
       "2021-07-09 -1.088800 -0.857029 -1.527478 -0.708259 -1.027867  0.027247   \n",
       "\n",
       "               High4   Volume4     High5   Volume5  ...     High9   Volume9  \\\n",
       "Date                                                ...                       \n",
       "2021-07-01  1.475940 -0.667879  0.363923 -0.994569  ...  0.844598 -0.472524   \n",
       "2021-07-06  1.380511 -0.947914  0.358200 -1.008901  ...  1.090795 -0.697455   \n",
       "2021-07-07  1.318762 -1.285036  0.335304 -1.016158  ...  1.161541  0.076385   \n",
       "2021-07-08  1.184038  0.130427  0.346752 -1.014162  ...  0.912515 -0.418365   \n",
       "2021-07-09  1.150357  0.385179  0.381095 -0.994569  ...  0.782341 -1.127800   \n",
       "\n",
       "              High10  Volume10    High11  Volume11    High12  Volume12  \\\n",
       "Date                                                                     \n",
       "2021-07-01  1.409164 -0.879394  1.691564 -0.295883  4.321024  3.646284   \n",
       "2021-07-06  1.353711 -1.023265  1.760297 -0.085782  6.375461  9.436822   \n",
       "2021-07-07  1.353711 -0.914688  1.442509 -0.065971  5.100747  1.914109   \n",
       "2021-07-08  1.314894 -1.020692  1.473237 -0.136613  4.866830  3.994090   \n",
       "2021-07-09  1.329451 -0.899615  1.610702 -0.392853  3.913641  0.683074   \n",
       "\n",
       "              High13  Volume13  \n",
       "Date                            \n",
       "2021-07-01  1.284563  1.580122  \n",
       "2021-07-06  1.401762  0.295484  \n",
       "2021-07-07  1.128299 -0.227887  \n",
       "2021-07-08  0.996075  0.438222  \n",
       "2021-07-09  1.191406  0.628538  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560eed2e",
   "metadata": {},
   "source": [
    "### Next Step\n",
    "Based on our task, we plan to use data to perform clustering, association analysis, and prediction. Clustering is used to cluster the stocks to see which stocks are closer to each other. Association analysis is used to discover relationships between stocks and give recommendations based on the relationships. Prediction is used to predict the stock's future performance for a certain period. Based on the result of the three tasks, we will give suggestions for the portfolio.\n",
    "In our task, there are a few challenges. First, for our prediction task, we will use today as the cutoff of training data and test data to have test data to test our prediction. The test data will have the stock price from 11/9/2022 to 12/2/2022. We will only perform analysis on historical data so that we can test our model accuracy in a completely independent dataset. The second one is feature engineering because our analysis can only build models for some past price values. The value of stock price has a high correlation for dates close to each other. To reduce correlation, we will aggregate the data in financial measures and create features such as seven-day and ten-day averages. So in a new data frame, each row will have each company, whether they are a renewable energy company, and their aggregate features. We may add new features in the future process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
